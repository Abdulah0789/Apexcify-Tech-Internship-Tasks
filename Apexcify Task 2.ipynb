{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae95cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! Ask me anything about Python. (Type 'exit' to quit)\n",
      "Chatbot: I am sorry, I don't understand that question.\n",
      "Chatbot: Python is a high-level, interpreted programming language known for its simplicity.\n",
      "Chatbot: In Python, you can write a comment by starting the line with a # symbol.\n",
      "Chatbot: Variables are containers for storing data values.\n",
      "Chatbot: I am sorry, I don't understand that question.\n",
      "Chatbot: I am sorry, I don't understand that question.\n",
      "Chatbot: Bye!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Step 1: Download NLTK resources (Run once) ---\n",
    "nltk.download('punkt') # For tokenization\n",
    "nltk.download('wordnet') # For lemmatization\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# --- Step 2: The Dataset (Knowledge Base) ---\n",
    "# In a real app, this would come from a CSV or Database\n",
    "faqs = {\n",
    "    \"What is Python?\": \"Python is a high-level, interpreted programming language known for its simplicity.\",\n",
    "    \"How do I install Python?\": \"You can download Python from the official website python.org.\",\n",
    "    \"What are variables?\": \"Variables are containers for storing data values.\",\n",
    "    \"How do I write a comment?\": \"In Python, you can write a comment by starting the line with a # symbol.\",\n",
    "    \"Bye\": \"Goodbye! Have a great day coding.\"\n",
    "}\n",
    "\n",
    "# Separate questions and answers for processing\n",
    "known_questions = list(faqs.keys())\n",
    "answers = list(faqs.values())\n",
    "\n",
    "# --- Step 3: Preprocessing Function ---\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # 3. Tokenization (splitting into list of words)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 4. Lemmatization (converting words to base form, e.g., 'running' -> 'run')\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess the known questions immediately\n",
    "cleaned_known_questions = [preprocess_text(q) for q in known_questions]\n",
    "\n",
    "# --- Step 4: The Chatbot Logic ---\n",
    "def get_response(user_input):\n",
    "    # Clean the user's input\n",
    "    cleaned_input = preprocess_text(user_input)\n",
    "    \n",
    "    # Add user input to the list of questions to compare them all together\n",
    "    all_texts = cleaned_known_questions + [cleaned_input]\n",
    "    \n",
    "    # Vectorization (Convert text to numbers using TF-IDF)\n",
    "    # This matrix counts how important specific words are\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Calculate Cosine Similarity\n",
    "    # Compare the user's input (last item in matrix) with all known questions\n",
    "    user_vector = tfidf_matrix[-1]\n",
    "    question_vectors = tfidf_matrix[:-1]\n",
    "    \n",
    "    similarity_scores = cosine_similarity(user_vector, question_vectors)\n",
    "    \n",
    "    # Find the index of the highest score\n",
    "    best_match_index = np.argmax(similarity_scores)\n",
    "    best_score = similarity_scores[0][best_match_index]\n",
    "    \n",
    "    # Threshold: If similarity is too low, say \"I don't understand\"\n",
    "    if best_score < 0.2: \n",
    "        return \"I am sorry, I don't understand that question.\"\n",
    "    else:\n",
    "        return answers[best_match_index]\n",
    "\n",
    "# --- Step 5: Simple Chat Interface ---\n",
    "print(\"Chatbot: Hello! Ask me anything about Python. (Type 'exit' to quit)\")\n",
    "\n",
    "while True:\n",
    "    user_text = input(\"You: \")\n",
    "    if user_text.lower() == 'exit':\n",
    "        print(\"Chatbot: Bye!\")\n",
    "        break\n",
    "    \n",
    "    response = get_response(user_text)\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb96ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0938b7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\MR ENGINEER\n",
      "[nltk_data]     SOLUTION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 1: Download NLTK resources (Run once) ---\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca71fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Step 1: Download NLTK resources (Safe Method) ---\n",
    "# This block handles the download safely to avoid lookup errors\n",
    "resources = ['punkt_tab', 'punkt', 'wordnet', 'omw-1.4']\n",
    "for resource in resources:\n",
    "    try:\n",
    "        nltk.data.find(f'tokenizers/{resource}')\n",
    "    except LookupError:\n",
    "        nltk.download(resource, quiet=True)\n",
    "\n",
    "# --- Step 2: The Dataset (Knowledge Base) ---\n",
    "faqs = {\n",
    "    \"What is Python?\": \"Python is a high-level, interpreted programming language known for its simplicity.\",\n",
    "    \"How do I install Python?\": \"You can download Python from the official website python.org.\",\n",
    "    \"What are variables?\": \"Variables are containers for storing data values.\",\n",
    "    \"How do I write a comment?\": \"In Python, you can write a comment by starting the line with a # symbol.\",\n",
    "    \"Bye\": \"Goodbye! Have a great day coding.\"\n",
    "}\n",
    "\n",
    "known_questions = list(faqs.keys())\n",
    "answers = list(faqs.values())\n",
    "\n",
    "# --- Step 3: Preprocessing Function ---\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess known questions once at startup\n",
    "cleaned_known_questions = [preprocess_text(q) for q in known_questions]\n",
    "\n",
    "# --- Step 4: The Chatbot Logic ---\n",
    "def get_response(user_input):\n",
    "    cleaned_input = preprocess_text(user_input)\n",
    "    \n",
    "    # Add user input to the database list temporarily\n",
    "    all_texts = cleaned_known_questions + [cleaned_input]\n",
    "    \n",
    "    # Vectorize\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Compare\n",
    "    user_vector = tfidf_matrix[-1]\n",
    "    question_vectors = tfidf_matrix[:-1]\n",
    "    \n",
    "    similarity_scores = cosine_similarity(user_vector, question_vectors)\n",
    "    best_match_index = np.argmax(similarity_scores)\n",
    "    best_score = similarity_scores[0][best_match_index]\n",
    "    \n",
    "    if best_score < 0.2: \n",
    "        return \"I am sorry, I don't understand that question.\"\n",
    "    else:\n",
    "        return answers[best_match_index]\n",
    "\n",
    "# --- Step 5: The GUI (Graphical User Interface) ---\n",
    "def send_message():\n",
    "    # 1. Get text from the input box\n",
    "    user_text = entry_box.get()\n",
    "    \n",
    "    if user_text.strip() != \"\":\n",
    "        # 2. Display User's message in the chat window\n",
    "        chat_window.config(state=tk.NORMAL) # Unlock the window to write\n",
    "        chat_window.insert(tk.END, \"You: \" + user_text + \"\\n\")\n",
    "        \n",
    "        # 3. Get Bot Response\n",
    "        bot_response = get_response(user_text)\n",
    "        chat_window.insert(tk.END, \"Bot: \" + bot_response + \"\\n\\n\")\n",
    "        \n",
    "        # 4. Auto-scroll to the bottom and lock the window\n",
    "        chat_window.see(tk.END)\n",
    "        chat_window.config(state=tk.DISABLED)\n",
    "        \n",
    "        # 5. Clear the input box\n",
    "        entry_box.delete(0, tk.END)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Python FAQ Chatbot\")\n",
    "root.geometry(\"400x500\")\n",
    "root.resizable(width=False, height=False)\n",
    "\n",
    "# Chat Window (Where messages appear)\n",
    "chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=50, height=20, state=tk.DISABLED)\n",
    "chat_window.pack(padx=10, pady=10)\n",
    "\n",
    "# Input Box (Where you type)\n",
    "entry_box = tk.Entry(root, width=40)\n",
    "entry_box.pack(padx=10, pady=5)\n",
    "\n",
    "# Bind the 'Enter' key to send message\n",
    "entry_box.bind(\"<Return>\", lambda event: send_message())\n",
    "\n",
    "# Send Button\n",
    "send_button = tk.Button(root, text=\"Send\", command=send_message, bg=\"#4CAF50\", fg=\"white\")\n",
    "send_button.pack(pady=5)\n",
    "\n",
    "# Start the GUI\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
